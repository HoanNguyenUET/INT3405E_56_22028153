{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":81933,"databundleVersionId":9643020,"sourceType":"competition"}],"dockerImageVersionId":30762,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras import layers, models, optimizers\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\nfrom sklearn.model_selection import train_test_split\nimport pandas as pd\nimport numpy as np\nimport os","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-09-26T14:06:24.480609Z","iopub.execute_input":"2024-09-26T14:06:24.481533Z","iopub.status.idle":"2024-09-26T14:06:24.923824Z","shell.execute_reply.started":"2024-09-26T14:06:24.481492Z","shell.execute_reply":"2024-09-26T14:06:24.922812Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"physical_devices = tf.config.list_physical_devices('GPU')\nif len(physical_devices) > 0:\n    tf.config.experimental.set_memory_growth(physical_devices[0], True)","metadata":{"execution":{"iopub.status.busy":"2024-09-26T14:06:27.362114Z","iopub.execute_input":"2024-09-26T14:06:27.363275Z","iopub.status.idle":"2024-09-26T14:06:27.367953Z","shell.execute_reply.started":"2024-09-26T14:06:27.363234Z","shell.execute_reply":"2024-09-26T14:06:27.366808Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"series_folder = '/kaggle/input/child-mind-institute-problematic-internet-use/series_train.parquet'\ntrain_csv_path = '/kaggle/input/child-mind-institute-problematic-internet-use/train.csv'\ntest_csv_path='/kaggle/input/child-mind-institute-problematic-internet-use/test.csv'","metadata":{"execution":{"iopub.status.busy":"2024-09-26T14:06:30.616241Z","iopub.execute_input":"2024-09-26T14:06:30.616896Z","iopub.status.idle":"2024-09-26T14:06:30.62118Z","shell.execute_reply.started":"2024-09-26T14:06:30.616858Z","shell.execute_reply":"2024-09-26T14:06:30.620285Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_df= pd.read_csv(test_csv_path)\ncolumns= test_df.columns","metadata":{"execution":{"iopub.status.busy":"2024-09-26T14:56:19.105946Z","iopub.execute_input":"2024-09-26T14:56:19.10634Z","iopub.status.idle":"2024-09-26T14:56:19.116639Z","shell.execute_reply.started":"2024-09-26T14:56:19.106302Z","shell.execute_reply":"2024-09-26T14:56:19.115878Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def load_and_preprocess_tabular_data(csv_path,columns=columns):\n    df = pd.read_csv(csv_path)\n    extras=[]\n    for i in df.columns:\n        if i not in columns:\n            extras.append(i)\n    extras.append('id')\n    # Separate labels (sii)\n    if 'sii' in df.columns:\n        y = df['sii']\n        X = df.drop(columns=extras)  # Remove 'id' and 'sii' for preprocessing\n    else:\n        y= None\n        X = df.drop(columns=['id'])\n    # Identify numeric and categorical columns\n    numeric_cols = X.select_dtypes(include=['float64', 'int64']).columns\n    categorical_cols = X.select_dtypes(include=['object']).columns\n\n    # Convert numeric columns to float (in case they contain string numbers)\n    X[numeric_cols] = X[numeric_cols].apply(pd.to_numeric, errors='coerce')\n\n    # Fill missing values: Numeric columns filled with mean, Categorical with mode\n    X[numeric_cols] = X[numeric_cols].fillna(X[numeric_cols].mean())\n    X[categorical_cols] = X[categorical_cols].fillna(X[categorical_cols].mode().iloc[0])\n    \n    # Label encode categorical columns\n    for col in categorical_cols:\n        X[col] = LabelEncoder().fit_transform(X[col].astype(str))  # Handle string types safely\n    \n    return X, y, df['id']","metadata":{"execution":{"iopub.status.busy":"2024-09-26T14:58:29.815181Z","iopub.execute_input":"2024-09-26T14:58:29.815575Z","iopub.status.idle":"2024-09-26T14:58:29.824966Z","shell.execute_reply.started":"2024-09-26T14:58:29.815542Z","shell.execute_reply":"2024-09-26T14:58:29.823946Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def scale_features(X_train, X_test=None, scaler=None):\n    # Create a new scaler if one is not provided (for training data)\n    if scaler is None:\n        scaler = StandardScaler()\n\n    # Fit and transform training data\n    X_train_scaled = scaler.fit_transform(X_train)\n\n    # Check if test data is provided, if so, transform it using the fitted scaler\n    if X_test is not None:\n        X_test_scaled = scaler.transform(X_test)\n        return X_train_scaled, X_test_scaled, scaler\n    else:\n        return X_train_scaled, None, scaler\n","metadata":{"execution":{"iopub.status.busy":"2024-09-26T14:58:33.226383Z","iopub.execute_input":"2024-09-26T14:58:33.226781Z","iopub.status.idle":"2024-09-26T14:58:33.233269Z","shell.execute_reply.started":"2024-09-26T14:58:33.226746Z","shell.execute_reply":"2024-09-26T14:58:33.232278Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def load_time_series_data(series_folder, ids, max_timesteps=500):\n    time_series_data = []\n\n    for _id in ids:\n        series_path = os.path.join(series_folder, f\"id={_id}/part-0.parquet\")\n        if os.path.exists(series_path):\n            series_df = pd.read_parquet(series_path)\n            series_df.fillna(0, inplace=True)  # Fill NaN values in time-series data\n            \n            # Truncate or pad time series to the same length\n            truncated_series = series_df[['X', 'Y', 'Z', 'enmo']].values[:max_timesteps]\n            if truncated_series.shape[0] < max_timesteps:\n                padding = np.zeros((max_timesteps - truncated_series.shape[0], 4))\n                truncated_series = np.vstack([truncated_series, padding])\n            time_series_data.append(truncated_series)\n        else:\n            # If no data for the ID, use all zeros\n            time_series_data.append(np.zeros((max_timesteps, 4)))\n    \n    return np.array(time_series_data)","metadata":{"execution":{"iopub.status.busy":"2024-09-26T14:58:36.049618Z","iopub.execute_input":"2024-09-26T14:58:36.050451Z","iopub.status.idle":"2024-09-26T14:58:36.057821Z","shell.execute_reply.started":"2024-09-26T14:58:36.050407Z","shell.execute_reply":"2024-09-26T14:58:36.056841Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from tensorflow.keras import layers\n\ndef build_dual_head_model(input_shape_tabular, input_shape_series):\n    input_shape_tabular = (input_shape_tabular,)  # Convert scalar to tuple (e.g., (80,))\n    \n    # Tabular input head\n    input_tabular = layers.Input(shape=input_shape_tabular, name=\"tabular_input\")\n    x1 = layers.Dense(128, activation='relu')(input_tabular)\n    x1 = layers.BatchNormalization()(x1)  # Add batch normalization\n    x1 = layers.Dense(64, activation='relu')(x1)\n    x1 = layers.BatchNormalization()(x1)  # Add batch normalization\n    x1 = layers.Dense(32, activation='relu')(x1)\n    x1 = layers.BatchNormalization()(x1)  # Add batch normalization\n\n    # Time-series input head\n    input_series = layers.Input(shape=input_shape_series, name=\"time_series_input\")\n    x2 = layers.Conv1D(32, kernel_size=3, activation='relu')(input_series)\n    x2 = layers.BatchNormalization()(x2)  # Add batch normalization\n    x2 = layers.MaxPooling1D(pool_size=2)(x2)\n    x2 = layers.Conv1D(64, kernel_size=3, activation='relu')(x2)\n    x2 = layers.BatchNormalization()(x2)  # Add batch normalization\n    x2 = layers.GlobalAveragePooling1D()(x2)\n\n    # Concatenate both heads\n    concatenated = layers.concatenate([x1, x2])\n    x = layers.Dense(64, activation='relu')(concatenated)\n    x = layers.BatchNormalization()(x)  # Add batch normalization\n    output = layers.Dense(4, activation='softmax')(x)  # 3-class classification for 'sii'\n\n    model = models.Model(inputs=[input_tabular, input_series], outputs=output)\n    return model\n","metadata":{"execution":{"iopub.status.busy":"2024-09-26T14:58:39.348134Z","iopub.execute_input":"2024-09-26T14:58:39.348837Z","iopub.status.idle":"2024-09-26T14:58:39.3589Z","shell.execute_reply.started":"2024-09-26T14:58:39.348797Z","shell.execute_reply":"2024-09-26T14:58:39.357869Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def custom_loss(y_true, y_pred):\n    mask = tf.cast(tf.not_equal(y_true, -1), tf.float32)  # Ignore NaN labels (-1 in this case)\n    loss = tf.keras.losses.SparseCategoricalCrossentropy()(y_true, y_pred)\n    return tf.reduce_mean(loss * mask)\n\n# 6. Compile the model\ndef compile_model(model):\n    # Compile the model with RMSprop\n    opt = optimizers.Adam(learning_rate=1e-3)  # Try RMSprop\n    model.compile(optimizer=opt, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n\n    return model","metadata":{"execution":{"iopub.status.busy":"2024-09-26T14:58:41.679736Z","iopub.execute_input":"2024-09-26T14:58:41.68012Z","iopub.status.idle":"2024-09-26T14:58:41.686547Z","shell.execute_reply.started":"2024-09-26T14:58:41.680084Z","shell.execute_reply":"2024-09-26T14:58:41.685366Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def train_model(model, X_tabular_train, X_series_train, y_train, epochs=20, batch_size=32):\n    history = model.fit([X_tabular_train, X_series_train], y_train, \n                        epochs=epochs, \n                        batch_size=batch_size, \n                        validation_split=0.2)\n    return history\n\n# 8. Inference and saving predictions\ndef predict_and_save(model, X_tabular_test, X_series_test, ids_test, output_csv):\n    predictions = model.predict([X_tabular_test, X_series_test])\n    predicted_labels = np.argmax(predictions, axis=1)\n    \n    # Create DataFrame for predictions\n    result_df = pd.DataFrame({\n        'id': ids_test,\n        'sii': predicted_labels\n    })\n    \n    # Save to CSV\n    result_df.to_csv(output_csv, index=False)","metadata":{"execution":{"iopub.status.busy":"2024-09-26T14:58:44.290763Z","iopub.execute_input":"2024-09-26T14:58:44.291505Z","iopub.status.idle":"2024-09-26T14:58:44.297917Z","shell.execute_reply.started":"2024-09-26T14:58:44.291467Z","shell.execute_reply":"2024-09-26T14:58:44.296956Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_tabular, y_train, ids_train = load_and_preprocess_tabular_data(train_csv_path)\n    \n    # Separate out labeled data (drop NaN labels)\nlabeled_mask = ~y_train.isna()\nX_tabular_train = X_tabular[labeled_mask]\ny_train = y_train[labeled_mask].astype(int)  # Drop NaNs in y_train\n    \n    # 2. Scale features\nX_tabular_train_scaled, _, scaler = scale_features(X_tabular_train)\n\n    # 3. Load corresponding time-series data\nX_series_train = load_time_series_data(series_folder, ids_train[labeled_mask])\n\n    # 4. Prepare the shapes for the model\ninput_shape_tabular = X_tabular_train_scaled.shape[1]  # Number of tabular features\ninput_shape_series = X_series_train.shape[1:]  # Shape of time-series (timesteps, features)\n","metadata":{"execution":{"iopub.status.busy":"2024-09-26T14:58:47.264141Z","iopub.execute_input":"2024-09-26T14:58:47.265007Z","iopub.status.idle":"2024-09-26T14:59:13.472591Z","shell.execute_reply.started":"2024-09-26T14:58:47.264968Z","shell.execute_reply":"2024-09-26T14:59:13.471727Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model = build_dual_head_model(input_shape_tabular, input_shape_series)\nmodel = compile_model(model)","metadata":{"execution":{"iopub.status.busy":"2024-09-26T14:59:13.474023Z","iopub.execute_input":"2024-09-26T14:59:13.474351Z","iopub.status.idle":"2024-09-26T14:59:13.583248Z","shell.execute_reply.started":"2024-09-26T14:59:13.474317Z","shell.execute_reply":"2024-09-26T14:59:13.582487Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Check tabular data for NaN/Inf\nprint(f\"Tabular data has NaN: {np.any(np.isnan(X_tabular_train_scaled))}\")\nprint(f\"Tabular data has Inf: {np.any(np.isinf(X_tabular_train_scaled))}\")\n\n# Check time-series data for NaN/Inf\nprint(f\"Time-series data has NaN: {np.any(np.isnan(X_series_train))}\")\nprint(f\"Time-series data has Inf: {np.any(np.isinf(X_series_train))}\")\n\n# Check labels for NaN/Inf\nprint(f\"Labels have NaN: {np.any(np.isnan(y_train))}\")\nprint(f\"Labels have Inf: {np.any(np.isinf(y_train))}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-09-26T14:59:35.447629Z","iopub.execute_input":"2024-09-26T14:59:35.448355Z","iopub.status.idle":"2024-09-26T14:59:35.464804Z","shell.execute_reply.started":"2024-09-26T14:59:35.448317Z","shell.execute_reply":"2024-09-26T14:59:35.463883Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_tabular_train_scaled.max()","metadata":{"execution":{"iopub.status.busy":"2024-09-26T14:59:39.976619Z","iopub.execute_input":"2024-09-26T14:59:39.977578Z","iopub.status.idle":"2024-09-26T14:59:39.984743Z","shell.execute_reply.started":"2024-09-26T14:59:39.977526Z","shell.execute_reply":"2024-09-26T14:59:39.983857Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(np.unique(y_train)) ","metadata":{"execution":{"iopub.status.busy":"2024-09-26T14:59:43.712546Z","iopub.execute_input":"2024-09-26T14:59:43.712925Z","iopub.status.idle":"2024-09-26T14:59:43.718562Z","shell.execute_reply.started":"2024-09-26T14:59:43.71289Z","shell.execute_reply":"2024-09-26T14:59:43.717564Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"history = train_model(model, X_tabular_train_scaled, X_series_train, y_train, epochs=20, batch_size=32)","metadata":{"execution":{"iopub.status.busy":"2024-09-26T14:59:46.71276Z","iopub.execute_input":"2024-09-26T14:59:46.713133Z","iopub.status.idle":"2024-09-26T15:00:02.309603Z","shell.execute_reply.started":"2024-09-26T14:59:46.713098Z","shell.execute_reply":"2024-09-26T15:00:02.308775Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_tabular_test, _, ids_test = load_and_preprocess_tabular_data(test_csv_path)  # No sii column here\nX_tabular_test_scaled, _, _ = scale_features(X_tabular_test, scaler=scaler)","metadata":{"execution":{"iopub.status.busy":"2024-09-26T15:00:31.668002Z","iopub.execute_input":"2024-09-26T15:00:31.668407Z","iopub.status.idle":"2024-09-26T15:00:31.733211Z","shell.execute_reply.started":"2024-09-26T15:00:31.668373Z","shell.execute_reply":"2024-09-26T15:00:31.732385Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_series_test = load_time_series_data('/kaggle/input/child-mind-institute-problematic-internet-use/series_test.parquet', ids_test)","metadata":{"execution":{"iopub.status.busy":"2024-09-26T15:00:35.595195Z","iopub.execute_input":"2024-09-26T15:00:35.595615Z","iopub.status.idle":"2024-09-26T15:00:35.649537Z","shell.execute_reply.started":"2024-09-26T15:00:35.595577Z","shell.execute_reply":"2024-09-26T15:00:35.648678Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"predict_and_save(model, X_tabular_test_scaled, X_series_test, ids_test, 'predictions.csv')","metadata":{"execution":{"iopub.status.busy":"2024-09-26T15:00:37.900025Z","iopub.execute_input":"2024-09-26T15:00:37.900424Z","iopub.status.idle":"2024-09-26T15:00:38.474316Z","shell.execute_reply.started":"2024-09-26T15:00:37.900387Z","shell.execute_reply":"2024-09-26T15:00:38.473266Z"},"trusted":true},"outputs":[],"execution_count":null}]}